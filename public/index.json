[{"content":"","date":null,"permalink":"/tags/data/","section":"Tags","summary":"","title":"Data"},{"content":"","date":null,"permalink":"/tags/data-mining/","section":"Tags","summary":"","title":"Data Mining"},{"content":"This section contains all my current posts.\n","date":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":null,"permalink":"/","section":"Profile","summary":"","title":"Profile"},{"content":"","date":null,"permalink":"/tags/python/","section":"Tags","summary":"","title":"Python"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/tags/web-scraping/","section":"Tags","summary":"","title":"Web Scraping"},{"content":"üåê Web Scraping in Static Websites #ü§î What is Web Scraping? #Have you ever thought about the vast amount of text data continuously exposed on social media, blogs, or internet forums? For example, the amount of data that can be extracted from tweets about a specific topic or the information publicly shared by users on specialized forums. Wouldn\u0026rsquo;t it be incredible to use this data to quantify, analyze, and even train a specialized LLM (Large Language Model) on a specific topic? Well, that\u0026rsquo;s exactly what web scraping does! It allows you to retrieve and explore data from websites, making it possible to extract valuable information for further use.\nüï∞Ô∏è When to Use Web Scraping? #Web scraping should be used when you have publicly available data on a website that is of interest to you. This means information that is freely shared and accessible. It should not be used on private websites or those handling personal or sensitive data, such as pages requiring login credentials or access to private information.\nWeb scraping is ideal for:\nPublic blogs Social media platforms (with public data) Open forums For example, I used web scraping in my LLM Poetry Generator project to gather data from a Spanish poetry website. The available datasets online were too small, so I decided to scrape my own. Keep reading to learn how I did it! üòä\nüõ†Ô∏è How to Use Web Scraping? #To understand web scraping, it\u0026rsquo;s important to classify websites into two types:\nDynamic Websites: Like social media platforms, which use varied structures to share information. Static Websites: Like blogs, which use HTML to describe their content. In this guide, we\u0026rsquo;ll focus on static websites since they are easier to scrape.\nüìÑ A Quick Introduction to HTML #To scrape data effectively, you need to understand how HTML structures content. HTML uses tags to define different parts of a webpage, such as titles, body text, images, external links, etc. Here\u0026rsquo;s a quick example of HTML tags:\n\u0026lt;h1\u0026gt;This is a Title\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This is a paragraph.\u0026lt;/p\u0026gt; \u0026lt;a href=\u0026#34;https://example.com\u0026#34;\u0026gt;This is a link\u0026lt;/a\u0026gt; \u0026lt;img src=\u0026#34;image.jpg\u0026#34; alt=\u0026#34;An image\u0026#34;\u0026gt; Understanding these tags is crucial because they help you identify where the data you want to scrape is located on the webpage.\nüîç Extracting the Data #Once you understand HTML tags and the structure of your target website, you can start extracting data. However, web scraping is not a one-size-fits-all solution. Each website is unique, and your scraping approach must be adapted to the specific structure of the site.\nLet me walk you through an example: I scraped approximately 13,000 Spanish poems from the website www.poemas-del-alma.com. Here\u0026rsquo;s how I did it:\nStep 1: Explore the Website Structure\nI started by analyzing the website\u0026rsquo;s structure. I noticed that I needed to:\nFirst, retrieve a list of authors. Then, get the list of poem titles for each author. Finally, extract the text of each poem using the author and title information. Step 2: Extract Authors\nUsing the browser\u0026rsquo;s Developer Tools (F12), I inspected the HTML and found that the \u0026lt;a\u0026gt; tag contained the links to individual authors. I used this tag to extract all author links.\nStep 3: Extract Poem Titles\nFor each author, I accessed their page and extracted the poem titles. I noticed that poem links were the only ones containing \u0026quot;https\u0026quot; and \u0026quot;.htm\u0026quot;, so I filtered out other links.\nStep 4: Extract Poem Text\nFinally, I looped through each poem link and extracted the text using the \u0026lt;p\u0026gt; tag, which contained the poem\u0026rsquo;s body.\nüß∞ Tools for Web Scraping #For static websites, I used Python along with the BeautifulSoup library to implement the scraping script. Here\u0026rsquo;s a breakdown of the tools I used:\nPython: The programming language used for scripting. BeautifulSoup: A Python library for parsing HTML and extracting data. Requests: A library to send HTTP requests and retrieve webpage content. You can check out the full script I used for scraping poems on my GitHub repository:\nüîó Web Scraping Script üìä Bonus: The Dataset #If you\u0026rsquo;re interested in exploring the dataset I created, you can find it on Kaggle:\nüîó Spanish Poetry Dataset\nüöÄ Conclusion #Web scraping is a powerful technique for extracting data from websites, especially when publicly available datasets are insufficient. By understanding HTML structure and using tools like Python and BeautifulSoup, you can gather and analyze data for various applications, such as training machine learning models or conducting research.\nIf you\u0026rsquo;re new to web scraping, start with static websites and gradually explore more complex scraping techniques. Happy scraping! üï∑Ô∏è\nüìå Tags ##Python #WebScraping #Data #DataMining #BeautifulSoup #HTML\n","date":"17 March 2025","permalink":"/posts/first_post/","section":"Posts","summary":"What? How? When? Everything you need to know about web scraping (HTML-based)","title":"Web Scraping in Static Websites"},{"content":"Feel free to reach out to me! Whether you have a question, a project idea, or just want to connect, I\u0026rsquo;m always open to new opportunities and collaborations.\nüìß Email # jgarnicaaza@gmail.com\nüìû Phone # +33 07 49 18 53 45\nüåê Social Media #You can also find me on these platforms:\nLinkedIn : Eduardo Garnica GitHub : jgarnicaaza üìç Location #I\u0026rsquo;m currently based in Toulouse, France. If you\u0026rsquo;re nearby, let\u0026rsquo;s grab a coffee! ‚òï\nüìÖ Schedule a Meeting #If you\u0026rsquo;d like to schedule a meeting, feel free to send me an email, and we can arrange a time that works for both of us!\nLet\u0026rsquo;s Connect! ü§ù #I\u0026rsquo;m always excited to hear about new projects, ideas, or just to chat about technology, engineering, or anything else. Don\u0026rsquo;t hesitate to reach out!\n","date":null,"permalink":"/contact/","section":"üì® Contact Me","summary":"","title":"üì® Contact Me"},{"content":"This section contains all my current projects.\n","date":null,"permalink":"/projects/","section":"Projects","summary":"","title":"Projects"},{"content":"","date":null,"permalink":"/tags/genai/","section":"Tags","summary":"","title":"GenAI"},{"content":"üñãÔ∏è GenAI Poetry: An AI Writing Poetry #We are currently living in a technological and computational revolution. Artificial intelligence models have become a key tool in our daily lives, enhancing productivity and even serving as a source of recreation.\nAs a poetry lover, I wanted to combine these two passions: the ancient art of poetry and the cutting-edge technology of AI. This project was born out of my desire to find inspiration for writing my own poetry. üòä\nIn this post, I\u0026rsquo;ll walk you through the stages of the project, from data acquisition to web deployment. I\u0026rsquo;ll keep it concise and not too technical‚Äîthis is more of a personal recount than a step-by-step manual. Enjoy!\nDon\u0026rsquo;t forget to check out the repository for more technical details: üîó GenAI Project üìÇ Data Acquisition #To train the model, I needed a large dataset of poems in both English and Spanish. For English, I found a suitable dataset on Kaggle. However, for Spanish, the available datasets were either too small or incomplete. So, I decided to scrape a poetry website to gather my own dataset. You can read more about the web scraping process in my Web Scraping blog post.\nIn the end, I had:\n14,000 poems in English 13,000 poems in Spanish üßπ Data Cleaning #Having the data was just the first step. Ensuring its quality was crucial. I faced several questions during this phase:\nShould I clean spaces and line breaks? Should I remove stopwords? How should I normalize the data? To answer these questions, I focused on the final product I wanted to deliver: a model that generates a poem based on a prompt (the first line) and produces up to 200 words in a single stanza, with proper line breaks for aesthetic appeal.\nThe cleaning process involved:\nNormalizing line breaks. Dropping excessively long or short poems. Ensuring the final output had the necessary line breaks for readability. ü§ñ Model Selection and Training #I chose GPT-2 for fine-tuning because it is lightweight, easy to fine-tune, and deployable without requiring extensive computational resources. Since my hardware was limited, I used Google Colab for training, leveraging the Hugging Face library to load the pre-trained GPT-2 model and fine-tune it with my dataset. The training process took approximately 7 hours.\nüöÄ Model Deployment #I wanted the model to be accessible to everyone, so I decided to deploy it as a web application. Here\u0026rsquo;s how I did it:\nBackend: Built with FastAPI. Frontend: Developed using Streamlit. Containerization: Packaged the application into a Docker container. Deployment: Used AWS EC2 to host the application, making it publicly accessible. üìä Results #The results were promising! The model generates coherent and creative poems based on the input prompt. However, there was a minor issue: the model sometimes mixed English and Spanish in the output. This happened because I didn\u0026rsquo;t add a language tag during data preprocessing. Regenerating the poem with the same prompt usually fixed the issue.\nHere\u0026rsquo;s an example of a poem generated in English:\nüåü Conclusion #This project was a fascinating journey into the intersection of art and technology. By combining my love for poetry with the power of AI, I created a tool that can inspire and generate beautiful poems. While there are still improvements to be made, the results are already impressive.\nIf you\u0026rsquo;re interested in exploring the project further, check out the GitHub repository and try out the web application!\nüìå Tags ##LLM #GenAI #Poetry #MachineLearning #WebDeployment #GPT2 #HuggingFace\n","date":"26 February 2025","permalink":"/projects/genai/","section":"Projects","summary":"An AI writing poetry? Really?!","title":"GenAI Poetry based on LLM"},{"content":"","date":null,"permalink":"/tags/llm/","section":"Tags","summary":"","title":"LLM"},{"content":"","date":null,"permalink":"/tags/machine-learning/","section":"Tags","summary":"","title":"Machine Learning"},{"content":"","date":null,"permalink":"/tags/poetry/","section":"Tags","summary":"","title":"Poetry"},{"content":"","date":null,"permalink":"/tags/web-deployment/","section":"Tags","summary":"","title":"Web Deployment"},{"content":"","date":null,"permalink":"/edu/","section":"","summary":"","title":""},{"content":"","date":null,"permalink":"/tags/automation/","section":"Tags","summary":"","title":"Automation"},{"content":"","date":null,"permalink":"/tags/education/","section":"Tags","summary":"","title":"Education"},{"content":"","date":null,"permalink":"/tags/electronics/","section":"Tags","summary":"","title":"Electronics"},{"content":"","date":null,"permalink":"/tags/international-experience/","section":"Tags","summary":"","title":"International Experience"},{"content":"üéì National Institute of Applied Sciences (INSA Toulouse) #üîó Official Program Website #As part of the High Academic Performance Program (PMP) at the National University of Colombia, I was selected to join an internationalization group. This opportunity led me to my second major academic experience: pursuing a Double Degree in Engineering at the National Institute of Applied Sciences (INSA Toulouse) in the specialization of Automation and Electronics.\nüåç About the Program #In 2022, I began the two-year Master\u0026rsquo;s program (M2 level) at INSA Toulouse. This journey allowed me to:\nTravel and explore new cultures. Learn a new language (French). Build meaningful connections with peers and professionals from around the world. This experience was incredibly enriching, providing me with both technical knowledge and soft skills that have shaped my personal and professional growth.\nüìö Key Courses and Topics #During my time at INSA Toulouse, I studied a variety of subjects that complemented my engineering background. Some of the most notable courses included:\nMachine Learning: Supervised and unsupervised algorithms. Analog Architectures for Embedded Systems (Architectures analogiques des syst√®mes embarqu√©s). Software Engineering and Networks (Informatique Logicielle et r√©seaux). Applied Automation (Automatique appliqu√©e). Computer Architecture (Architecture informatique). Cloud Computing. üõ†Ô∏è Skills Developed #This program not only enhanced my technical expertise but also helped me develop essential soft skills, including:\nMulticultural Awareness: Working in a diverse and international environment. Language Proficiency: Improving my French and communication skills. Teamwork: Collaborating on projects with students from different backgrounds. Adaptability: Thriving in new and challenging environments. üíº Professional Experience #During my time at INSA Toulouse, I gained valuable professional experience through:\nSummer Internship: Completed during the first year of the program. Work-Study Program (Alternance): Spent the entire second year alternating between academic studies and professional work in an industrial setting. For more details about my professional experiences, feel free to check out my Professional Experiences page. :)\nüåü Why This Experience Mattered #Studying at INSA Toulouse was a transformative experience that allowed me to:\nExpand my technical knowledge in cutting-edge fields. Grow personally by adapting to a new culture and language. Build a global network of peers and professionals. This journey has prepared me to tackle complex challenges in the fields of electronics and automation while embracing a global perspective.\nüìå Tags ##Education #Electronics #Automation #INSA_Toulouse #InternationalExperience #STEM\n","date":"26 October 2024","permalink":"/edu/insa/","section":"","summary":"National Institute of Applied Sciences (INSA Toulouse)","title":"Master's Degree in Electronics and Automation"},{"content":"","date":null,"permalink":"/exp/","section":"","summary":"","title":""},{"content":"","date":null,"permalink":"/tags/cnn/","section":"Tags","summary":"","title":"CNN"},{"content":"","date":null,"permalink":"/tags/computer-vision/","section":"Tags","summary":"","title":"Computer Vision"},{"content":"","date":null,"permalink":"/tags/deep-learning/","section":"Tags","summary":"","title":"Deep Learning"},{"content":"","date":null,"permalink":"/tags/embedded-systems/","section":"Tags","summary":"","title":"Embedded Systems"},{"content":"","date":null,"permalink":"/tags/professional-experience/","section":"Tags","summary":"","title":"Professional Experience"},{"content":"Work-Study Program (Alternance) #üöÄ Overview #After completing my internship at Occion, the company that had subcontracted me, Keyia, offered me a position in their work-study program (alternance) to continue advancing the Strigoo project. Strigoo is a sensor developed for detecting road actors such as pedestrians, bicycles, and vehicles. This opportunity allowed me to combine my final year of university studies with professional work, gaining hands-on experience in embedded systems and deep learning.\nThe goal was to implement a deep learning algorithm that would be more robust in detecting road actors. However, the hardware limitations posed a significant challenge: 1MB of RAM! This constraint required innovative solutions to optimize the algorithm and make it feasible for deployment on embedded systems.\nüõ†Ô∏è Key Contributions #1. Algorithm Optimization #To address the hardware limitations, I implemented several optimization techniques:\nBinarization: Reduced the complexity of image processing. Morphological Operations: Improved image quality by removing noise and enhancing shapes. Image Filters: Applied various filters to make images lighter and faster to process. 2. Deep Learning Architectures #I explored and tested several neural network architectures to find the most efficient solution:\nYOLOv8: Known for its real-time object detection capabilities. FOMO: A lightweight model optimized for embedded systems. MobileNetV2: Designed for mobile and embedded devices with limited resources. Custom Network: A tailored architecture designed specifically for this project. 3. Model Training and Deployment # Trained the models using a dataset of labeled images. Exported the models using TensorFlow Lite for deployment on embedded systems. Achieved an accuracy of 92% with the custom network. Implemented pruning and quantization techniques to reduce the model size to under 1MB, making it suitable for the microcontroller\u0026rsquo;s limited resources. üìä Results # Accuracy: Achieved 92% accuracy in detecting road actors. Model Size: Reduced the model size to under 1MB using pruning and quantization. Deployment: Successfully implemented the model on the embedded system, enabling real-time detection. üéì Skills Acquired #This experience allowed me to develop a wide range of skills, including:\nDeep Learning: Understanding of neural network architectures, training, and optimization. Computer Vision: Techniques for image processing and object detection. Embedded Systems: Working with hardware constraints and optimizing algorithms for resource-limited environments. MLOps: Best practices for deploying and maintaining machine learning models. Agile Methodology: Collaborative development and iterative improvement. üñºÔ∏è Custom Network Architecture #The final solution was based on a custom network architecture, similar to the one shown in the following diagram:\nüåü Conclusion #This work-study program was a transformative experience that allowed me to apply theoretical knowledge to real-world challenges. I gained expertise in deep learning, computer vision, and embedded systems, while also developing soft skills such as teamwork and project management. The successful implementation of the Strigoo sensor demonstrates the potential of combining academic learning with professional practice to create innovative solutions.\nüìå Tags ##CNN #DeepLearning #EmbeddedSystems #ComputerVision #ProfessionalExperience\n","date":"25 September 2024","permalink":"/exp/keyia/","section":"","summary":"Deep Learning on Embedded Systems for Computer Vision","title":"Work-Study Program (Alternance)"},{"content":"","date":null,"permalink":"/tags/engineering/","section":"Tags","summary":"","title":"Engineering"},{"content":"üöÄ Occion #üîó Official Website #Occion is a start-up based in Gaillac-Brens, France, focused on developing innovative electronic solutions. During my 4-month internship, I was recruited as a stagiaire to work on improving the detection algorithm for a sensor designed to classify public road actors, such as pedestrians, cars, motorcycles, bicycles, and more, using a camera and image data analysis.\nüéØ Project Overview #The goal of the project was to enhance the accuracy and robustness of the sensor\u0026rsquo;s detection algorithm. The sensor is an embedded system, meaning the algorithm had to run locally without relying on cloud processing. Here\u0026rsquo;s how the project evolved:\nInitial Approach #The initial algorithm used a decision tree based on differences between consecutive frames. Parameters such as object size, elongation, density, and curvature were used to define thresholds for classifying each type of actor. However, this method only achieved an accuracy of 55%, which was not robust enough for real-world applications.\nüõ†Ô∏è My Role and Contributions #As the lead developer for this algorithm, I proposed and implemented a supervised learning approach to improve its performance. Here\u0026rsquo;s a breakdown of my work:\n1. Data Collection #I began by collecting a substantial dataset of road actors. This involved manually creating a table where each object was described by its characteristics. For example:\nObject Area Elongation Density Curvature \u0026hellip; Car 4500 75 80 20 \u0026hellip; Pedestrian 850 90 90 0 \u0026hellip; Motorcycle 1200 85 70 15 \u0026hellip; Bicycle 600 80 60 10 \u0026hellip; This table represented each object as a vector based on pixel differences between frames caused by their movement, 2000 objects were registered.\n2. Model Training #Using this dataset, I trained and compared several supervised learning algorithms. The Random Forest model emerged as the best performer, achieving an accuracy of 85%‚Äîa significant improvement over the initial decision tree.\n3. Data Annotation for Future Improvements #To further enhance the algorithm, I collected and labeled a dataset of 5,000 images featuring various road actors. I used Roboflow, an open-source platform, to manage and version these images in the cloud. This dataset laid the groundwork for future implementations of deep learning models to achieve even higher performance.\nüñºÔ∏è Example Image #Here‚Äôs an example of the labeled images used for training:\nüöÄ Results and Impact #By the end of my internship, I had successfully:\nImproved the algorithm\u0026rsquo;s accuracy from 55% to 85% using Random Forest. Created a robust dataset of 5,000 labeled images for future deep learning implementations. Set the stage for transitioning to more advanced models, such as convolutional neural networks (CNNs), to further enhance performance. üåü Key Takeaways #This internship allowed me to:\nGain hands-on experience in machine learning and embedded systems. Develop skills in data collection, model training, and performance optimization. Work in a collaborative environment to solve real-world problems. üìå Tags ##Engineering #MachineLearning #EmbeddedSystems #ComputerVision #Internship #Occion\n","date":"1 June 2023","permalink":"/exp/occion/","section":"","summary":"Machine Learning Internship on Embedded Systems","title":"Summer Internship"},{"content":"üéì National University of Colombia #üîó Mechatronics Engineering Program Website #The National University of Colombia is the most prestigious and largest university in the country. My time there was filled with hard work, dedication, fun, and, most importantly, immense learning. I hold a deep affection for my alma mater, as it was where I truly understood the essence of life. Additionally, it provided me with the opportunity to pursue further studies abroad, as you\u0026rsquo;ll see in my next post.\nüèõÔ∏è About the University #The National University of Colombia is renowned for its academic excellence and commitment to research and innovation. Studying here allowed me to develop not only technical skills but also critical thinking, a passion for learning, and problem-solving abilities.\nüìö Key and Foundational Courses #The Mechatronics Engineering program is a blend of mathematics, control systems, mechanics, programming, and more. Below is a list of the most relevant courses I took during my studies:\nMathematics: From differential calculus to complex variable calculus, including differential equations. Probability and Statistics System Modeling and Advanced Control Robotics Artificial Intelligence Techniques Digital and Analog Electronics Static and Dynamic Mechanical Modeling Data Structures Object-Oriented Programming Manufacturing Process Automation üåü Skills Developed #During my time at the National University of Colombia, I gained a wide range of skills, including:\nMathematical Modeling: Ability to model and analyze complex systems. Programming: Proficiency in various programming languages and paradigms. Critical Thinking: Enhanced ability to approach problems methodically. Teamwork: Collaborating on multidisciplinary projects. Innovation: Applying theoretical knowledge to real-world challenges. üöÄ Next Steps #My experience at the National University of Colombia laid the foundation for my academic and professional journey. It opened doors to international opportunities, which I will share in my next post. Stay tuned!\nüìå Tags ##Education #Mechatronics #Engineering #NationalUniversityOfColombia #STEM\n","date":"10 December 2022","permalink":"/edu/unal/","section":"","summary":"National University of Colombia","title":"Bachelor's Degree in Mechatronics Engineering"},{"content":"","date":null,"permalink":"/tags/mechatronics/","section":"Tags","summary":"","title":"Mechatronics"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"}]